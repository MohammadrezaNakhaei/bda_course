---
title: Bayesian data analysis -- reading instructions 6
---

# Chapter 6

Outline of the chapter 6

-   6.1 The place of model checking in applied Bayesian statistics

-   6.2 Do the inferences from the model make sense?

-   6.3 Posterior predictive checking ($p$-values can be skipped)

-   6.4 Graphical posterior predictive checks (this can be skimmed, see
    instead the paper *Visualization in Bayesian workflow*)

-   6.5 Model checking for the educational testing example

R and Python demos at
<https://avehtari.github.io/BDA_course_Aalto/demos.html>

-   demo6_1: Posterior predictive checking - light speed

-   demo6_2: Posterior predictive checking - sequential dependence

-   demo6_3: Posterior predictive checking - poor test statistic

-   demo6_4: Posterior predictive checking - marginal predictive p-value

Find all the terms and symbols listed below. When reading the chapter,
write down questions related to things unclear for you or things you
think might be unclear for others.

-   model checking

-   sensitivity analysis

-   external validation

-   posterior predictive checking

-   joint posterior predictive distribution

-   marginal (posterior) predictive distribution

-   self-consistency check

-   replicated data

-   $y^{\mathop{\mathrm{\mathrm{rep}}}}$, $\tilde{y}$, $\tilde{x}$

-   test quantities

-   discrepancy measure

-   tail-area probabilities

-   classical $p$-value

-   posterior predictive $p$-values

-   multiple comparisons

-   marginal predictive checks

-   cross-validation predictive distributions

-   conditional predictive ordinate

# Replicates vs. future observation

Predictive $\tilde{y}$ is the next not yet observed possible
observation. $y^{\mathrm{rep}}$ refers to replicating the whole
experiment (with same values of $x$) and obtaining as many replicated
observations as in the original data.

# Posterior predictive $p$-values

Section 6.3 discusses posterior predictive $p$-values, which we don't
recommend any more especially in a form of hypothesis testing.

# Prior predictive checking

Prior predictive checking using just the prior predictive distributions
is very useful tool for assessing the sensibility of the model and
priors even before observing any data or before doing the posterior
inference. See additional reading below for examples.

# Additional reading

The following article has some useful discussion and examples also about
prior and posterior predictive checking.

-   Gabry, Simpson, Vehtari, Betancourt, and Gelman (2018).
    Visualization in Bayesian workflow. *Journal of the Royal
    Statistical Society Series A*, , 182(2):389-402.
    <https://doi.org/10.1111/rssa.12378>.

-   Video of the paper presentation
    <https://www.youtube.com/watch?v=E8vdXoJId8M>

And some useful demos

-   Graphical posterior predictive checks using the bayesplot package\
    <http://mc-stan.org/bayesplot/articles/graphical-ppcs.html>

-   Another demo
    [demos_rstan/ppc/poisson-ppc.Rmd](http://avehtari.github.io/BDA_R_demos/demos_rstan/ppc/poisson-ppc.html)
